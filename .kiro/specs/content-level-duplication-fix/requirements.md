# Requirements Document

## Introduction

The vibehuntr-agent currently suffers from content-level duplication where the LLM generates the same paragraphs or sentences multiple times within a single response. This is distinct from streaming-level duplication (which is already handled by hash-based chunk detection). Content-level duplication occurs when the LLM itself repeats information, possibly due to tool calls being executed multiple times or the model regenerating the same summary. This significantly degrades user experience and undermines trust in the agent.

## Glossary

- **Content-Level Duplication**: When the same semantic content (paragraphs, sentences) appears multiple times in a single agent response
- **Streaming-Level Duplication**: When the same chunk is yielded multiple times during the streaming process (already handled)
- **Sentence Similarity**: A measure of how similar two sentences are, using sequence matching algorithms
- **Accumulated Response**: The complete text generated by the agent so far in the current turn
- **Duplicate Detector**: The system component responsible for identifying and preventing duplicate content

## Requirements

### Requirement 1

**User Story:** As a user, I want the agent to provide non-repetitive responses, so that I receive clear and concise information without redundant content.

#### Acceptance Criteria

1. WHEN the agent generates a response, THEN the system SHALL detect if any sentence or paragraph is semantically similar to content already in the accumulated response
2. WHEN duplicate content is detected at the sentence level, THEN the system SHALL filter out the duplicate portion before yielding it to the user
3. WHEN the system detects content-level duplication, THEN it SHALL log the detection with details about what was duplicated and where
4. WHEN a response is complete, THEN the system SHALL verify that no paragraphs appear more than once in the final output
5. WHEN duplicate content is filtered, THEN the system SHALL maintain the coherence and flow of the remaining response

### Requirement 2

**User Story:** As a developer, I want detailed logging of content-level duplication events, so that I can diagnose and fix the root causes of repetition.

#### Acceptance Criteria

1. WHEN content-level duplication is detected, THEN the system SHALL log the duplicate text preview (first 100 characters)
2. WHEN content-level duplication is detected, THEN the system SHALL log the similarity score that triggered the detection
3. WHEN content-level duplication is detected, THEN the system SHALL log the position in the accumulated response where the similar content was found
4. WHEN a response completes, THEN the system SHALL include content-level duplication statistics in the response metadata
5. WHEN multiple duplications occur in a single response, THEN the system SHALL track and report each occurrence separately

### Requirement 3

**User Story:** As a system administrator, I want configurable similarity thresholds for duplicate detection, so that I can tune the sensitivity based on observed behavior.

#### Acceptance Criteria

1. WHEN initializing the duplicate detector, THEN the system SHALL accept a configurable similarity threshold parameter (0.0 to 1.0)
2. WHEN comparing sentences for similarity, THEN the system SHALL use the configured threshold to determine if content is duplicate
3. WHEN the similarity threshold is set to 1.0, THEN only exact matches SHALL be considered duplicates
4. WHEN the similarity threshold is set to 0.8, THEN sentences with 80% or higher similarity SHALL be considered duplicates
5. WHEN no threshold is specified, THEN the system SHALL use a default value of 0.85

### Requirement 4

**User Story:** As a developer, I want the duplicate detection to work efficiently, so that it doesn't significantly impact response streaming performance.

#### Acceptance Criteria

1. WHEN processing a new chunk, THEN the system SHALL only compare against recent sentences (last 50 sentences) rather than the entire accumulated response
2. WHEN splitting text into sentences, THEN the system SHALL use efficient regex-based splitting rather than complex NLP parsing
3. WHEN calculating similarity, THEN the system SHALL use Python's built-in SequenceMatcher for performance
4. WHEN duplicate detection adds latency, THEN the added latency SHALL be less than 50ms per chunk on average
5. WHEN duplicate detection fails, THEN the system SHALL gracefully degrade and yield the content anyway rather than crash

### Requirement 5

**User Story:** As a user, I want the system to handle edge cases gracefully, so that duplicate detection doesn't cause errors or unexpected behavior.

#### Acceptance Criteria

1. WHEN a chunk contains only whitespace or punctuation, THEN the system SHALL skip duplicate detection for that chunk
2. WHEN a chunk is very short (less than 10 characters), THEN the system SHALL skip sentence-level duplicate detection
3. WHEN sentence splitting fails, THEN the system SHALL fall back to paragraph-level comparison
4. WHEN similarity calculation raises an exception, THEN the system SHALL log the error and allow the content through
5. WHEN the accumulated response is empty, THEN the system SHALL skip duplicate detection and yield the first chunk immediately
